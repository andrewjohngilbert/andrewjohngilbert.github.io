

<p align="center">
<img src="{{ site.baseurl }}/assets/images/EdDinner.jpg" alt="andrew gilbert"/>
</p>
[Centre for Creative Arts and Technologies](https://c-cats.ac/)
Department of Music and Media, Faculty of Arts and Social Sciences, University of Surrey

# Biography
I am an  Associate Professor at the University of Surrey. Before joining becoming a Lecturer, I obtained my PhD from CVSSP with Richard Bowden. My research interests include Computer Vision, video understanding and Generative Models.

My Research ranges from research in intelligent creative arts such as fine grained style search and movie trailer genre understanding and 4D performance capture. Through to enabling machines to perceive and understand their surroundings with real-time accurate 3D human pose estimation for large-scale markerless motion capture for use both indoors and outdoors,  complex realistic activity recognition and early work on tracking people on vast surveillance networks.

I have published over 50 articles in the leading international vision conferences and journals providing state of the art advancements in this field.

 I'm a member of the [British Machine Vision Association (BMVA)](http://www.bmva.org/) Executive committee and coordinate the national BMVA technical meetings. bringing together key expert from industry and academia to discuss and identify solutions to current problems in specialist areas of the computer vision and machine learning field.

# Updates



# PhD Students
I'm always looking for good PhD candidates but normally when I have funding available it is for UK students. This is sometimes due to restrictions on the funding but more often than not more to do with the difference between home and overseas fees. However, if you are an exceptional candidate, then drop me an email. I am happy to work with high calibre candidates to obtain scholarships either internally or from external funders such as the China Scholarship Council or the Commonwealth Scholarship Council.

## Current PhD Students

- Adrienne Deganutti - Long Term Video Captioning 2023
- Xu Dong - Group Activity recognition in Video 2023
- Mona Ahmadian - Self Supervised Audio Visual Video Understanding 2022
- [Soon Yau](https://www.linkedin.com/in/soonyau/) - Text to Storyboard generation - 2021
- [Kar Balan] - Decentralized virtual content Understanding for Blockchain- 2021
- Katharina Botel-Azzinnaro - Real stories through faked media: Non-fiction in AI-generated environments 2021
- [Dan Ruta](https://danruta.co.uk/) - Exploring and understanding fine grained style - 2019
- [Ed Fish](https://ed-fish.github.io/) - Film Trailer Genre Understanding and exploration - 2019
- Tony Orme - Temporal Prediction of IP packets in network switches - 2019
​- Rob Penhaligon  - 2019

## Alumi
- [Violeta Menendez Gonzalez](https://www.linkedin.com/in/violetamenendez/) - Novel viewpoint and stereo inpainting - 2019
- [Kary Ho](https://www.linkedin.com/in/kary-ho-484a3b1aa) 2019
- [Mat Trumble](http://scholar.google.co.uk/citations?user=iKylkAgAAAAJ) - 2015
- [Phil Krejov](https://www.linkedin.com/in/krejov/) - 2012
- [Segun Oshin](https://www.linkedin.com/in/olusegun-oshin/) - 2008

# Recent Research





## 2024

### [PLOT-TAL--Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization](https://andrewjohngilbert.github.io/PLOT-TAL/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/PLOT-TAL/">
  <img src="{{ site.baseurl }}/assets/images/PLotal_teaser.jpg" width="400"/>
</a>
</p>
Ed Fish, Jon Weinbren, Andrew Gilbert, ArXiv abs/2403.18915, 2024

## 2023

### [ViscoNet: Bridging and Harmonizing Visual and Textual Conditioning for ControlNet](https://soon-yau.github.io/visconet/)
<p align="left">
<a href="https://soon-yau.github.io/visconet/">
  <img src="{{ site.baseurl }}/assets/images/ViscoNet_Teaser.jpg" width="400"/>
</a>
</p>
Soon Cheong, Armin Mustafa, Andrew Gilbert, ArXiv abs/2312.03154, 2023

### [Multi-Resolution Audio-Visual Feature Fusion for Temporal Action Localization](https://andrewjohngilbert.github.io/Multi-TAL/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/Multi-TAL/">
  <img src="{{ site.baseurl }}/assets/images/Multi_TAL_Teaser.jpg" width="400"/>
</a>
</p>
Ed Fish, Jon Weinbren, Andrew Gilbert, NeurIPS 2023 Workshop on Machine Learning for Audio, 2023

### [MOFO: MOtion FOcused Self-Supervisionfor Video Understanding](https://andrewjohngilbert.github.io/mofo/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/mofo/">
  <img src="{{ site.baseurl }}/assets/images/mofo_teaser.png" width="400"/>
</a>
</p>
Mona Ahmadian, Frank Guerin, Andrew Gilbert, NeurIPS 2023 Workshop Self-Supervised Learning: Theory and Practice, 2023

### [UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer](https://github.com/soon-yau/upgpt)
<p align="left">
<a href="https://github.com/soon-yau/upgpt">
  <img src="{{ site.baseurl }}/assets/images/UPGPTmodel.jpg" width="400"/>
</a>
</p>
Soon Cheong, Armin Mustafa, Andrew Gilbert, ICCVWS'23 2nd computer vision for Metaverse workshop, 2023

### [Diff-nst: Diffusion interleaving for deformable neural style transfer](https://andrewjohngilbert.github.io/diffnst)
<p align="left">
<a href="https://andrewjohngilbert.github.io/diffnst">
  <img src="{{ site.baseurl }}/assets/images/diffnst_teaser.jpg" width="400"/>
</a>
</p>
Dan Ruta, Gemma C Tarrés, Andrew Gilbert, Eli Shechtman, Nick Kolkin, John Collomosse, arXiv abs/2307.04157, 2023


### [DECORAIT - DECentralized Opt-in/out Registry for AI Training](https://andrewjohngilbert.github.io/Decorait/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/Decorait/">
  <img src="{{ site.baseurl }}/assets/images/Decorait_teaser.png" width="400"/>
</a>
</p>
 Kar Balan, Alex Black, Simon Jenni, Andy Parsons, Andrew Gilbert, John Collomosse. The 20th ACM SIGGRAPH European Conference on Visual Media Production (CVMP'23), 2023 - Best Paper


### [Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer](https://andrewjohngilbert.github.io/aladinnst)
<p align="left">
<a href="https://andrewjohngilbert.github.io/aladinnst">
  <img src="{{ site.baseurl }}/assets/images/aladinnst_teaser.jpg" width="400"/>
</a>
</p>
Dan Ruta, Gemma Canet Tarres, Alexander Black, Andrew Gilbert, John Collomosse, arXiv abs/2304.05755, 2023



### [NeAT: Neural Artistic Tracing for Beautiful Style Transfer](https://andrewjohngilbert.github.io/neat)
<p align="left">
<a href="https://andrewjohngilbert.github.io/neat">
  <img src="{{ site.baseurl }}/assets/images/neat_teaser.jpg" width="400"/>
</a>
</p>
Dan Ruta, Andrew Gilbert, John Collomosse, Eli Shechtman, Nicholas Kolkin, arXiv abs/2304.05139, 2023



### [Ekila: synthetic media provenance and attribution for generative art](https://github.com/andrewjohngilbert.github.io/ekila)
<p align="left">
<a href="https://github.com/andrewjohngilbert.github.io/ekila">
  <img src="{{ site.baseurl }}/assets/images/ekila_teaser.jpg" width="400"/>
</a>
</p>
Kar Balan, Shruti Agarwal, Simon Jenni, Andy Parsons, Andrew Gilbert, John Collomosse, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2023


 ## 2022