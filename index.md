

<p align="center">
<img src="{{ site.baseurl }}/assets/images/EdDinner.jpg" alt="andrew gilbert"/>
</p>
[Centre for Creative Arts and Technologies](https://c-cats.ac/)
Department of Music and Media, Faculty of Arts and Social Sciences, University of Surrey

# Biography

Dr Andrew Gilbert is an Associate Professor in Machine Learning at the University of Surrey, where he co-leads the interdisciplinary Centre for Creative Arts and Technologies ([C-CATS](https://c-cats.ac/)). His [research](https://scholar.google.co.uk/citations?hl=en&user=NNhnVwoAAAAJ) lies at the intersection of computer vision, generative modelling, and multimodal learning, with a particular focus on building interpretable and human-centred AI systems. His work aims to develop machines that not only see and recognise the world, but also understand and creatively respond to it.

Dr Gilbert has made significant contributions to the fields of video understanding, , [long-form video captioning](https://andrewjohngilbert.github.io/DANTE-AD/), [visual style modelling](https://andrewjohngilbert.github.io/neat), and [AI-driven story understanding](https://andrewjohngilbert.github.io/Rethinking_genre/). A distinctive feature of his research is its integration into the creative industries, applying technical advances to domains such as media production, [performance capture](https://cvssp.org/projects/totalcapture/TotalCapture/), and digital arts. From training models to [classify genre from movie trailers](https://andrewjohngilbert.github.io/Rethinking_genre/) to designing systems that can [generate synthetic images](https://andrewjohngilbert.github.io/Multitwine/) and narrative content, his work consistently pushes the boundaries of how AI can support and enhance human creativity.

He leads a [vibrant and diverse team](https://andrewjohngilbert.github.io/gilbertineweekendaway2024/) of PhD students, collaborating on cutting-edge projects in areas such as [self-supervised learning from video](https://andrewjohngilbert.github.io/mofo/), [video diffusion models](https://soon-yau.github.io/CameraMotionGuidance/), and multimodal scene understanding. Many of these projects are conducted in close partnership with creative practitioners, industry partners, and other academic disciplines, reflecting Dr Gilbert’s commitment to interdisciplinary and impact-driven research.

In addition to his research leadership, Dr Gilbert is an active contributor to the UK computer vision community. He serves on the [British Machine Vision Association (BMVA)](http://www.bmva.org/) Executive Committee, where he organises [national technical meetings](https://www.bmva.org/meetings) to foster collaboration between academia and industry. Through this work, he helps shape the research agenda for future AI systems that are explainable, responsible, and aligned with human values.



# PhD Students
I'm always looking for good PhD candidates, but normally, when I have funding available, it is for UK students. This is sometimes due to restrictions on the funding, but more often than not, it has more to do with the difference between home and overseas fees. However, if you are an exceptional candidate, email me. I am happy to work with high-calibre candidates to obtain scholarships either internally or from external funders such as the China Scholarship Council or the Commonwealth Scholarship Council.

## Current PhD Students

- [Oberon Buckingham-West](https://www.linkedin.com/in/oberon-dsbw) - Adaptive Game Engines for Personalised Learning 2024
- [Adrienne Deganutti](https://www.linkedin.com/in/adrienne-deganutti-bb28031b6/) - Long Term Video Captioning 2023
- [Xu Dong](https://www.linkedin.com/in/xudong-442302166/) - Group Activity Recognition in Video 2023
- [Sadegh Rahmani](https://www.linkedin.com/in/sadegh-rahmani-002b6398) - Human Inspire Video Understanding 2023
- [Mona Ahmadian](https://www.linkedin.com/in/mona-ahmadian-57853521a/) - Self-Supervised Audio Visual Video Understanding 2022
- [Kar Balan](https://www.linkedin.com/in/kar-balan/) - Decentralized virtual content Understanding for Blockchain- 2021
- [Katharina Botel-Azzinnaro](https://www.linkedin.com/in/katharinabotelazzinnaro/) - Real stories through faked media: Non-fiction in AI-generated environments 2021
- [Tony Orme](https://www.linkedin.com/in/tonyorme/) - Temporal Prediction of IP packets in network switches - 2019

## Alumi
- [Gemma Canet Tarrés ](https://www.linkedin.com/in/gemmacanettarres/) - Levering Multimodality for Controllable Image Generation 2021
- [Soon Yau](https://www.linkedin.com/in/soonyau/) - Text to Storyboard generation - 2021
- [Ed Fish](https://ed-fish.github.io/) - Film Trailer Genre Understanding and Exploration - 2019
- [Dan Ruta](https://danruta.co.uk/) - Exploring and understanding fine-grained style - 2019
- [Violeta Menendez Gonzalez](https://www.linkedin.com/in/violetamenendez/) - Novel viewpoint and stereo inpainting - 2019
- [Kary Ho](https://www.linkedin.com/in/kary-ho-484a3b1aa) 2019
- [Mat Trumble](http://scholar.google.co.uk/citations?user=iKylkAgAAAAJ) - 2015
- [Phil Krejov](https://www.linkedin.com/in/krejov/) - 2012
- [Segun Oshin](https://www.linkedin.com/in/olusegun-oshin/) - 2008

<p align="center">
<img src="{{ site.baseurl }}/assets/images/SoonEdGradCropSmall.jpg" width="300" alt="Ed Fish and Soon Graduation Andrew Gilbert"/>
</p>


# Gilbertine Weekend Away
Working together is crucial for my lab and PhD student, so we go on a yearly trip away
<p align="left">
<a href="https://andrewjohngilbert.github.io/gilbertineweekendaway2024/">
  <img src="{{ site.baseurl }}/assets/images/Gilbertine2024.jpg" width="300"/>
</a>
</p>


# Research Updates

## 2025

### [Human vs. Machine Minds: Ego-Centric Action Recognition Compared](https://andrewjohngilbert.github.io/HumanvsMachineMinds/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/HumanvsMachineMinds/">
  <img src="{{ site.baseurl }}/assets/images/HumanvsMachineMindsTeaserWide.jpg" width="400"/>
</a>
</p>
Sadegh Rahmani, Filip Rybansky, Quoc Vuong, Frank Guerin, Andrew Gilbert, IEEE/CVF Conference on Computer Vision and Pattern Recognition - Workshop on Multimodal Algorithmic Reasoning (MAR'25) , 2025

### [DANTE-AD: Dual-Vision Attention Network for Long-Term Audio Description](https://andrewjohngilbert.github.io/DANTE-AD/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/DANTE-AD/">
  <img src="{{ site.baseurl }}/assets/images/DANTE-ADWideTeaser.jpg" width="400"/>
</a>
</p>
Adrienne Deganutti, Simon Hadfield, Andrew Gilbert, Arxiv Preprint 2503.24096, 2025


### [Multitwine: Multi-Object Compositing with Text and Layout Control](https://andrewjohngilbert.github.io/multitwine/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/multitwine/">
  <img src="{{ site.baseurl }}/assets/images/mutitwine_teaserSingle.jpg" width="400"/>
</a>
</p>
Gemma C Tarrés, Zhe Lin, Zhifei Zhang, He Zhang, Andrew Gilbert, John Collomosse, Soo Ye Kim, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR'25) 2025

### [MultiNeRF: Multiple Watermark Embedding for Neural Radiance Fields](https://andrewjohngilbert.github.io/multinerf/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/multinerf/">
  <img src="{{ site.baseurl }}/assets/images/MultiNerf-teaser.png" width="400"/>
</a>
</p>
Yash Kulthe, Andrew Gilbert, John Collomosse, International Conference on Learning Representations (ICLR'25) - The 1st Workshop on GenAI Watermarking, 2025

## 2024

### [Boosting Camera Motion Control for Video Diffusion Transformers](https://soon-yau.github.io/CameraMotionGuidance/)
<p align="left">
<a href="https://soon-yau.github.io/CameraMotionGuidance/">
  <img src="{{ site.baseurl }}/assets/images/CamControlBoosting.png" width="400"/>
</a>
</p>
Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang, Arxiv Preprint 2410.10802, 2024


### [FILS: Self-Supervised Video Feature Prediction In Semantic Language Space](https://andrewjohngilbert.github.io/FILS/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/FILS/">
  <img src="{{ site.baseurl }}/assets/images/FILS_Teaser.jpg" width="400"/>
</a>
</p>
Mona Ahmadian, Frank Guerin, Andrew Gilbert, The 35th British Machine Vision Conference (BMVC'24) 2024

### [Interpretable Long-term Action Quality Assessment](https://andrewjohngilbert.github.io/InterpretAQA/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/InterpretAQA/">
  <img src="{{ site.baseurl }}/assets/images/IntrpretAQATeaser.png" width="400"/>
</a>
</p>
Xu Dong, Xinran Liu, Wanqing Li, Anthony Adeyemi-Ejeye,Andrew Gilbert, The 35th British Machine Vision Conference (BMVC'24) (Oral) 2024

### [PDFed: Privacy-Preserving and Decentralized Asynchronous Federated Learning for Diffusion Models](https://andrewjohngilbert.github.io/PDFed/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/PDFed/">
  <img src="{{ site.baseurl }}/assets/images/PDFed_Teaser.jpg" width="400"/>
</a>
</p>
Kar Balan, Andrew Gilbert, John Collomosse, Conference on Visual Media Production (CVMP'24) 2024

### [Detection and Re-Identification in the case of Horse Racing](https://andrewjohngilbert.github.io/HelmetDetect/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/HelmetDetect/">
  <img src="{{ site.baseurl }}/assets/images/HelmetDetect_Teaser.jpg" width="400"/>
</a>
</p>
Will Binning, Sadegh Rahmani, Xu Dong, Andrew Gilbert, Conference on Visual Media Production (CVMP'24) 2024

### [Thinking Outside the BBox: Unconstrained Generative Object Compositing](https://andrewjohngilbert.github.io/BBox/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/BBox/">
  <img src="{{ site.baseurl }}/assets/images/BBox_Teaser.png" width="400"/>
</a>
</p>
Gemma C Tarrés, Zhe Lin, Zhifei Zhang, Jianming Zhang, Yizhi Song, Dan Ruta, Andrew Gilbert, John Collomosse, Soo Ye Kim, European Conference on Computer Vision ECCV'24 2024

### [ViscoNet: Bridging and Harmonizing Visual and Textual Conditioning for ControlNet](https://soon-yau.github.io/visconet/)
<p align="left">
<a href="https://soon-yau.github.io/visconet/">
  <img src="{{ site.baseurl }}/assets/images/ViscoNet_Teaser.jpg" width="400"/>
</a>
</p>
Soon Cheong, Armin Mustafa, Andrew Gilbert, European Conference of Computer Vision 2024, FashionAI: Exploring the intersection of Fashion and Artificial Intelligence for reshaping the Industry, 2024

### [Diff-nst: Diffusion interleaving for deformable neural style transfer](https://andrewjohngilbert.github.io/diffnst)
<p align="left">
<a href="https://andrewjohngilbert.github.io/diffnst">
  <img src="{{ site.baseurl }}/assets/images/diffnst_teaser.jpg" width="400"/>
</a>
</p>
Dan Ruta, Gemma C Tarrés, Andrew Gilbert, Eli Shechtman, Nick Kolkin, John Collomosse, European Conference of Computer Vision 2024, Vision for Art (VISART VII) Workshop, 2024

### [Aladin-nst: Self-supervised disentangled representation learning of artistic style through neural style transfer](https://andrewjohngilbert.github.io/aladinnst)
<p align="left">
<a href="https://andrewjohngilbert.github.io/aladinnst">
  <img src="{{ site.baseurl }}/assets/images/aladinnst_teaser.png" width="400"/>
</a>
</p>
Dan Ruta, Gemma Canet Tarres, Alexander Black, Andrew Gilbert, John Collomosse, European Conference of Computer Vision 2024, Vision for Art (VISART VII) Workshop, 2024


### [NeAT: Neural Artistic Tracing for Beautiful Style Transfer](https://andrewjohngilbert.github.io/neat)
<p align="left">
<a href="https://andrewjohngilbert.github.io/neat">
  <img src="{{ site.baseurl }}/assets/images/neat_teaser.jpg" width="400"/>
</a>
</p>
Dan Ruta, Andrew Gilbert, John Collomosse, Eli Shechtman, Nicholas Kolkin, European Conference of Computer Vision 2024, Vision for Art (VISART VII) Workshop, 2024

### [Interpretable Action Recognition on Hard to Classify Actions](https://andrewjohngilbert.github.io/InterpretActions/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/InterpretActions/">
  <img src="{{ site.baseurl }}/assets/images/InterpretActions_Teaser.png" width="400"/>
</a>
</p>
Anastasia Anichenko, Frank Guerin, and Andrew Gilbert, European Conference of Computer Vision 2024, Human-inspired Computer Vision Workshop, 2024

### [DEAR: Depth-Estimated Action Recognition](https://andrewjohngilbert.github.io/dear/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/aear/">
  <img src="{{ site.baseurl }}/assets/images/dear_teaser.jpg" width="400"/>
</a>
</p>
Sadegh Rahmani, Filip Rybansky, Quoc Vuong, Frank Guerin, Andrew Gilbert, European Conference of Computer Vision 2024, Human-inspired Computer Vision Workshop, 2024

### [Towards Rapid Elephant Flow Detection Using Time Series Prediction for OTT Streaming](https://andrewjohngilbert.github.io/RapidElephant/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/RapidElephant/">
  <img src="{{ site.baseurl }}/assets/images/BMSB2024Teaser.jpg" width="400"/>
</a>
</p>
Anthony Orme,  Anthony Adeyemi-Ejeye and  Gilbert, Andrew, 19th IEEE International Symposium on Broadband Multimedia Systems and Broadcasting BMSB 2024

### [PLOT-TAL--Prompt Learning with Optimal Transport for Few-Shot Temporal Action Localization](https://andrewjohngilbert.github.io/PLOT-TAL/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/PLOT-TAL/">
  <img src="{{ site.baseurl }}/assets/images/PLotal_teaser.jpg" width="400"/>
</a>
</p>
Ed Fish, Jon Weinbren, Andrew Gilbert, ArXiv abs/2403.18915, 2024

## 2023

### [Multi-Resolution Audio-Visual Feature Fusion for Temporal Action Localization](https://andrewjohngilbert.github.io/Multi-TAL/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/Multi-TAL/">
  <img src="{{ site.baseurl }}/assets/images/Multi_TAL_Teaser.jpg" width="400"/>
</a>
</p>
Ed Fish, Jon Weinbren, Andrew Gilbert, NeurIPS 2023 Workshop on Machine Learning for Audio, 2023

### [MOFO: MOtion FOcused Self-Supervisionfor Video Understanding](https://andrewjohngilbert.github.io/mofo/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/mofo/">
  <img src="{{ site.baseurl }}/assets/images/mofo_teaser.png" width="400"/>
</a>
</p>
Mona Ahmadian, Frank Guerin, Andrew Gilbert, NeurIPS 2023 Workshop Self-Supervised Learning: Theory and Practice, 2023

### [UPGPT: Universal Diffusion Model for Person Image Generation, Editing and Pose Transfer](https://github.com/soon-yau/upgpt)
<p align="left">
<a href="https://github.com/soon-yau/upgpt">
  <img src="{{ site.baseurl }}/assets/images/UPGPTmodel.jpg" width="400"/>
</a>
</p>
Soon Cheong, Armin Mustafa, Andrew Gilbert, ICCVWS'23 2nd computer vision for Metaverse workshop, 2023

### [DECORAIT - DECentralized Opt-in/out Registry for AI Training](https://andrewjohngilbert.github.io/Decorait/)
<p align="left">
<a href="https://andrewjohngilbert.github.io/Decorait/">
  <img src="{{ site.baseurl }}/assets/images/Decorait_teaser.png" width="400"/>
</a>
</p>
 Kar Balan, Alex Black, Simon Jenni, Andy Parsons, Andrew Gilbert, John Collomosse. The 20th ACM SIGGRAPH European Conference on Visual Media Production (CVMP'23), 2023 - Best Paper

### [Ekila: synthetic media provenance and attribution for generative art](https://andrewjohngilbert.github.io/ekila)
<p align="left">
<a href="https://andrewjohngilbert.github.io/ekila">
  <img src="{{ site.baseurl }}/assets/images/Ekila_teaser.png" width="400"/>
</a>
</p>
Kar Balan, Shruti Agarwal, Simon Jenni, Andy Parsons, Andrew Gilbert, John Collomosse, IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, 2023

## 2022

SVS: Adversarial refinement for sparse novel view synthesis
VM González, A Gilbert, G Phillipson, S Jolly, S Hadfield
arXiv preprint arXiv:2211.07301	2	2022

Hypernst: Hyper-networks for neural style transfer
D Ruta, A Gilbert, S Motiian, B Faieta, Z Lin, J Collomosse
European Conference on Computer Vision, 201-217	5	2022

StyleBabel: artistic style tagging and captioning
D Ruta, A Gilbert, P Aggarwal, N Marri, A Kale, J Briggs, C Speed, H Jin, ...
European Conference on Computer Vision, 219-236	9	2022

Two-Stream Transformer Architecture for Long Form Video Understanding
E Fish, J Weinbren, A Gilbert
British Machine Vision Conference (BMVC)		2022

SaiNet: Stereo aware inpainting behind objects with generative networks
VM González, A Gilbert, G Phillipson, S Jolly, S Hadfield
arXiv preprint arXiv:2205.07014	1	2022

Kpe: Keypoint pose encoding for transformer-based image generation
SY Cheong, A Mustafa, A Gilbert
arXiv preprint arXiv:2203.04907	5	2022

## 2021

### [Rethinking genre classification with fine grained semantic clustering](https://andrewjohngilbert.github.io/Rethinking_genre)
<p align="left">
<a href="https://andrewjohngilbert.github.io/Rethinking_genre">
  <img src="{{ site.baseurl }}/assets/images/RethinkingGenre_teaser.png" width="400"/>
</a>
</p>
Ed Fish, Jon Weinbren, Andrew Gilbert, IEEE International Conference on Image Processing (ICIP), 2021

Neural architecture search for deep image prior
K Ho, A Gilbert, H Jin, J Collomosse
Computers & graphics 98, 188-196	37	2021

Human-like Relational Models for Activity Recognition in Video
J Chrol-Cannon, A Gilbert, R Lazic, A Madhusoodanan, F Guerin
arXiv preprint arXiv:2107.05319		2021

ALADIN: All Layer Adaptive Instance Normalization for Fine-grained Style Similarity
D Ruta, S Motiian, B Faieta, Z Lin, H Jin, A Filipkowski, A Gilbert, ...
arXiv preprint arXiv:2103.09776	23	2021

## 2019

Semantic estimation of 3d body shape and pose using minimal cameras
A Gilbert, M Trumble, A Hilton, J Collomosse
arXiv preprint arXiv:1908.03030	1	2019

Fusing visual and inertial sensors with semantics for 3d human pose estimation
A Gilbert, M Trumble, C Malleson, A Hilton, J Collomosse
International Journal of Computer Vision 127, 381-397	66	2019

Automatic image annotation at ImageCLEF
J Wang, A Gilbert, B Thomee, M Villegas
Information Retrieval Evaluation in a Changing World: Lessons Learned from …	3	2019

## 2018
Inpainting of wide-baseline multiple viewpoint video
A Gilbert, M Trumble, A Hilton, J Collomosse
IEEE Transactions on Visualization and Computer Graphics 26 (7), 2417-2428	4	2018

Deep autoencoder for combined human pose estimation and body model upscaling
M Trumble, A Gilbert, A Hilton, J Collomosse
Proceedings of the European Conference on Computer Vision (ECCV), 784-800	65	2018

Volumetric performance capture from minimal camera viewpoints
A Gilbert, M Volino, J Collomosse, A Hilton
Proceedings of the European Conference on Computer Vision (ECCV), 566-581	60	2018

Disentangling structure and aesthetics for style-aware image completion
A Gilbert, J Collomosse, H Jin, B Price
Proceedings of the IEEE Conference on Computer Vision and Pattern …	15	2018

## 2017
### [Total capture: 3d human pose estimation fusing video and inertial sensors](https://cvssp.org/projects/totalcapture/TotalCapture/)
<!--<p align="left">
<a href="[https://cvssp.org/projects/totalcapture/TotalCapture/]">
  <img src="{{ site.baseurl }}/assets/images/RethinkingGenre_teaser.png3" width="400"/>
</a>
</p>
-->
M Trumble, A Gilbert, C Malleson, A Hilton, J Collomosse. Proceedings of 28th British Machine Vision Conference, 1-13	290	2017



Total capture: 3d human pose estimation fusing video and inertial sensors


Image and video mining through online learning
A Gilbert, R Bowden
Computer Vision and Image Understanding 158, 72-84	10	2017

Guided optimisation through classification and regression for hand pose estimation
P Krejov, A Gilbert, R Bowden
Computer Vision and Image Understanding 155, 124-138	35	2017

Real-time Full-Body Motion Capture from Video and IMUs
C Malleson, A Gilbert, M Trumble, J Collomosse, A Hilton
92	2017

## 2016
Deep convolutional networks for marker-less human pose estimation from multiple views
M Trumble, A Gilbert, A Hilton, J Collomosse
Proceedings of the 13th European conference on visual media production (CVMP …	22	2016

Overview of the ImageCLEF 2016 Scalable Concept Image Annotation Task.
A Gilbert, L Piras, J Wang, F Yan, A Ramisa, E Dellandrea, ...
CLEF (Working Notes), 254-278	24	2016

Learning Markerless human pose estimation from multiple viewpoint video
M Trumble, A Gilbert, A Hilton, J Collomosse
Computer Vision–ECCV 2016 Workshops: Amsterdam, The Netherlands, October 8 …	4	2016

Learning multi-class discriminative patterns using episode-trees
RB Eng Jon Ong, Nicolas Pugeault, Andrew Gilbert
IARIA		2016

## 2015 
Geometric Mining: Scaling Geometric Hashing to Large Datasets
A Gilbert, R Bowden
3rd Workshop on Web-scale Vision and Social Media (VSM), at ICCV 2015	2	2015

Overview of the ImageCLEF 2015 Scalable Image Annotation, Localization and Sentence Generation task.
A Gilbert, L Piras, J Wang, F Yan, E Dellandrea, RJ Gaizauskas, ...
CLEF (Working Notes)	39	2015

Combining discriminative and model based approaches for hand pose estimation
P Krejov, A Gilbert, R Bowden
2015 11th IEEE international conference and workshops on automatic face and …	34	2015

Data mining for action recognition
A Gilbert, R Bowden
Computer Vision--ACCV 2014: 12th Asian Conference on Computer Vision …	5	2015

General overview of ImageCLEF at the CLEF 2015 labs
M Villegas, H Müller, A Gilbert, L Piras, J Wang, K Mikolajczyk, ...
Experimental IR Meets Multilinguality, Multimodality, and Interaction: 6th …	109	2015

## 2014

Capturing relative motion and finding modes for action recognition in the wild
O Oshin, A Gilbert, R Bowden
Computer Vision and Image Understanding 125, 155-171	17	2014

A multitouchless interface: expanding user interaction
P Krejov, A Gilbert, R Bowden
IEEE computer graphics and applications 34 (3), 40-48	8	2014

## 2012

Meeting in the Middle: A top-down and bottom-up approach to detect pedestrians
A Shaukat, A Gilbert, D Windridge, R Bowden
Proceedings of the 21st International Conference on Pattern Recognition …	3	2012

A picture is worth a thousand tags: automatic web based image tag expansion
A Gilbert, R Bowden
Asian Conference on Computer Vision, 447-460	10	2012

Data fusion in ubiquitous networked robot systems for urban services
L Merino, A Gilbert, J Capitán, R Bowden, J Illingworth, A Ollero
annals of telecommunications-annales des télécommunications 67, 355-375	15	2012

## 2011
igroup: Weakly supervised image and video grouping
A Gilbert, R Bowden
2011 International Conference on Computer Vision, 2166-2173	10	2011

Push and Pull: Iterative grouping of media
A Gilbert, R Bowden
British Machine Vision Conference 2011	2	2011

There is more than one way to get out of a car: Automatic Mode Finding for Action Recognition in the Wild
O Oshin, A Gilbert, R Bowden
Iberian Conference on Pattern Recognition and Image Analysis, 41-48		2011

Visualisation and prediction of conversation interest through mined social signals
D Okwechime, EJ Ong, A Gilbert, R Bowden
2011 IEEE International Conference on Automatic Face & Gesture Recognition …	6	2011

Capturing the relative distribution of features for action recognition
O Oshin, A Gilbert, R Bowden
2011 IEEE International Conference on Automatic Face & Gesture Recognition …	31	2011

Social interactive human video synthesis
D Okwechime, EJ Ong, A Gilbert, R Bowden
Computer Vision–ACCV 2010: 10th Asian Conference on Computer Vision …	6	2011

## 2010

Action recognition using mined hierarchical compound features
A Gilbert, J Illingworth, R Bowden
IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (5), 883-897	231	2010

Decentralized sensor fusion for ubiquitous networking robotics in urban areas
A Sanfeliu, J Andrade-Cetto, M Barbosa, R Bowden, J Capitán, ...
Sensors 10 (3), 2274-2314	60	2010

Learning to recognise spatio-temporal interest points
OT Oshin, A Gilbert, J Illingworth, R Bowden
Machine Learning for Human Motion Analysis: Theory and Practice, 14-30	1	2010

## 2009
Fast realistic multi-action recognition using mined dense spatio-temporal features
A Gilbert, J Illingworth, R Bowden
2009 IEEE 12th international conference on computer vision, 925-931	226	2009

Accurate fusion of robot, camera and wireless sensors for surveillance applications
A Gilbert, J Illingworth, R Bowden, J Capitan, L Merino
2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV …	7	2009

Action recognition using randomised ferns
O Oshin, A Gilbert, J Illingworth, R Bowden
2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV …	26	2009

## 2008
Incremental, scalable tracking of objects inter camera
A Gilbert, R Bowden
Computer Vision and Image Understanding 111 (1), 43-58	54	2008

Scalable and adaptable tracking of humans in multiple camera systems
A Gilbert
PQDT-UK & Ireland	3	2008


Scale invariant action recognition using compound features mined from dense spatio-temporal corners
A Gilbert, J Illingworth, R Bowden
Computer Vision–ECCV 2008: 10th European Conference on Computer Vision …	136	2008

Tracking objects across uncalibrated arbitrary topology camera networks
R Bowden, A Gilbert, P KaewTraKulPong
Intelligent Distributed Video Surveillance Systems, 157-182	6	2006

Poster Session II-Tracking and Motion-Tracking Objects Across Cameras by Incrementally Learning Inter-camera Colour Calibration and Patterns of Activity
A Gilbert, R Bowden
Lecture Notes in Computer Science 3952, 125-136		2006

Tracking objects across cameras by incrementally learning inter-camera colour calibration and patterns of activity
A Gilbert, R Bowden
Computer Vision–ECCV 2006: 9th European Conference on Computer Vision, Graz …
